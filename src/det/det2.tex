% Chapter 4, Section 2 _Linear Algebra_ Jim Hefferon
%  http://joshua.smcvt.edu/linearalgebra
%  2001-Jun-12
\section{Geometry of Determinants}
The prior section develops the determinant algebraically, by
considering formulas satisfying certain conditions.
This section complements that with a geometric approach.
Beyond its intuitive appeal, an advantage of this approach is that while 
we have so far only considered whether or not a determinant is zero,
here we shall give a meaning to the value of the determinant.
(The prior section treats the determinant as a function of the
rows but this section focuses on columns.)










\subsection{Determinants as Size Functions}
This parallelogram picture
is familiar from the construction of the sum of the two vectors.
\begin{center}
  \includegraphics{det/mp/ch4.30}
\end{center}

\begin{definition} \label{df:Box}
%<*df:Box>
In $\Re^n$
the \definend{box}\index{box}
(or \definend{parallelepiped}\index{parallelepiped})
formed by 
\( \sequence{\vec{v}_1,\dots,\vec{v}_n} \) 
is the set
\( \set{t_1\vec{v}_1+\dots+t_n\vec{v}_n
      \suchthat t_1,\ldots,t_n\in \closedinterval{0}{1}} \).
%</df:Box>
\end{definition}

\noindent Thus the parallelogram above is the box formed by 
$\sequence{\binom{x_1}{y_1},\binom{x_2}{y_2}}$.
A three-space box is shown in \nearbyexample{ex:VolParPiped}.

We can find the area of the above box by drawing an enclosing rectangle
and subtracting away areas not in the box.
\begin{center}
  \parbox{1.5in}{\hbox{}\hfil\includegraphics{det/mp/ch4.31}\hfil\hbox{}}
  \quad
  \parbox{3.0in}{
    \hbox{}\hfil
    $\begin{array}{l}
       \text{area of parallelogram}                    \\
         \hbox{}\quad \hbox{}
            =\text{area of rectangle}
                -\text{area of $A$}-\text{area of $B$} \\
         \hbox{}\qquad \hbox{}
            -\cdots-\text{area of $F$}                   \\
         \hbox{}\quad \hbox{}
            =(x_1+x_2)(y_1+y_2)-x_2y_1-x_1y_1/2        \\
         \hbox{}\qquad \hbox{}
            -x_2y_2/2-x_2y_2/2-x_1y_1/2-x_2y_1         \\
         \hbox{}\quad \hbox{}
            =x_1y_2-x_2y_1        
    \end{array}$
    \hfil\hbox{}}
\end{center}
That the area equals the value of the determinant
\begin{equation*}
  \begin{vmat}
    x_1  &x_2  \\
    y_1  &y_2
  \end{vmat}
  =x_1y_2-x_2y_1
\end{equation*}
is no coincidence.
The definition of determinants contains four properties that we know
lead to a unique function for each dimension~$n$.
We shall argue that these properties 
make good postulates for a function 
that measures the size of boxes in $n$-space.\index{size}

For instance, such a function 
should have the property that multiplying one of the box-defining vectors by
a scalar
will multiply the size by that scalar.
\begin{center}
  \includegraphics{det/mp/ch4.32}
  \qquad
  \includegraphics{det/mp/ch4.33}
\end{center}
Shown here is $k=1.4$.
On the right the rescaled region is in solid lines with the 
original region shaded for comparison.
% The region formed by $k\vec{v}$ and~$\vec{w}$
% is bigger by a factor of \( k \)
% than the shaded region enclosed by $\vec{v}$ and~$\vec{w}$.
% That is,
% \( \size (k\vec{v},\vec{w})=k\cdot\size (\vec{v},\vec{w}) \) and

That is, we can reasonably expect that
$\size (\dots,k\vec{v},\dots)=k\cdot\size (\dots,\vec{v},\dots)$.
Of course, this condition is one of those in
the definition of determinants.

Another property of determinants that should apply to any 
function measuring the size of a box is that
it is unaffected by row combinations.
Here are before-combining and 
after-combining boxes (the scalar shown is $k=-0.35$). 
\begin{center}
  \includegraphics{det/mp/ch4.34}
  \qquad
  \includegraphics{det/mp/ch4.35}
\end{center}   
The box formed by $v$ and 
$k\vec{v}+\vec{w}$ slants differently 
than the original one but the two have the
same base and the same height, and hence the same area.
% (As before, the figure on the right has the 
% original region in shade for comparison.)
So we expect that size is not affected by a shear operation
$\size (\dots,\vec{v},\dots,\vec{w},\dots)
=\size (\dots,\vec{v},\dots,k\vec{v}+\vec{w},\dots)$.
Again, this is a determinant condition.

We expect that the box formed by unit vectors has unit size
\begin{center}
  \includegraphics{det/mp/ch4.36}
\end{center}
and we naturally extend that to any $n$-space
$\size(\vec{e}_1,\dots,\vec{e}_n)=1$.
% Again, that is a determinant property.

Condition~(2) of the definition of determinant is 
redundant, as remarked following the definition.
We know from the prior section that 
for each~$n$ the determinant exists and is unique so we know  
that these postulates for size functions are consistent and 
that we do not need any more postulates.
Therefore, we are justified in 
interpreting \( \det(\vec{v}_1,\dots,\vec{v}_n) \) as giving the
size of the box formed by the vectors.
% (\textit{Comment.}
%   An even more basic approach, which also leads to the definition
%   below, is in \cite{Weston59}.)

\begin{remark}  \label{re:PropertyTwoGivesSign}
Although condition~(2) is redundant it raises an important point.
Consider these two.
\begin{center} \small
  \begin{tabular}{c@{\hspace*{8em}}c}
    \includegraphics{det/mp/ch4.37}  
      &\includegraphics{det/mp/ch4.38}  \\[.25ex]
    \ $\begin{vmat}[r]
        4  &1   \\
        2  &3
      \end{vmat}=10$
      &\ $\begin{vmat}[r]
          1  &4   \\
          3  &2
        \end{vmat}=-10$
  \end{tabular}
\end{center}
Swapping the columns changes the sign.
On the left, starting with $\vec{u}$ and following the
arc inside the angle to $\vec{v}$ (that is, going counterclockwise),
we get a positive size.
On the right, starting at $\vec{v}$ and going to~$\vec{u}$, 
and so following the clockwise arc, gives a negative size.
The sign returned by the size function reflects the 
\definend{orientation}\index{box!orientation}\index{orientation} 
or \definend{sense}\index{box!sense}\index{sense} of the box.
(We see the same thing if we picture the effect of scalar multiplication
by a negative scalar.)
% Although it is both interesting and important, we don't need the idea of
% orientation for the development below and so we will pass it by.
% (See \nearbyexercise{exer:BasisOrient}.)
\end{remark}

\begin{definition} \label{df:Volume}
%<*df:Volume>
The \definend{volume}\index{volume}\index{box!volume}
of a box is the absolute value of the determinant of
a matrix with those vectors as columns.
%</df:Volume>
\end{definition}

\begin{example} \label{ex:VolParPiped}
By the formula that takes the area of the
base times the height, the volume of this 
parallelepiped is $12$.
That agrees with the determinant.
\begin{center}
   \parbox{2in}{\hbox{}\hfil\includegraphics{det/asy/ppiped.pdf}\hfil\hbox{}}  
  %  \parbox{2in}{\hbox{}\hfil\includegraphics{det/mp/ch4.39}\hfil\hbox{}}  
  \hspace{4.5em}
  $\begin{vmat}[r]
     2 &0 &-1\\
     0 &3 &0 \\
     2 &1 &1
  \end{vmat}=12$
\end{center}
Taking the vectors in a different order changes the sign but
not the magnitude. 
\begin{equation*}
  \begin{vmat}[r]
     0  &2 &-1 \\
     3  &0 &0 \\
     1  &2 &1
  \end{vmat}=-12  
\end{equation*}
\end{example}

% The next result describes some of the geometry of the linear
% functions that act on
% \( \Re^n \). 

\begin{theorem}\label{th:MatChVolByDetMat}
\index{size}\index{transformation!size change}
%<*th:MatChVolByDetMat>
A transformation \( \map{t}{\Re^n}{\Re^n} \) changes the size of all boxes
by the same factor, namely, the size of the image of a box
$\deter{t(S)}$ is $\deter{T}$ times the size of the box $\deter{S}$,
where $T$ is the matrix
representing $t$ with respect to the standard basis.

That is, the determinant of a product is the
product of the determinants $\deter{TS}=\deter{T}\cdot\deter{S}$.
%</th:MatChVolByDetMat>
\end{theorem}

The two sentences say the same thing, first in map terms and then
in matrix terms. 
This is because
$\deter{t(S)}=\deter{TS}$, as both give the size of the box that is the
image of the unit box $\stdbasis_n$ under the composition $\composed{t}{s}$,
where the maps are represented with respect to the standard basis.
We will prove the second sentence.

\begin{proof}
%<*pf:MatChVolByDetMat0>
First consider the case that $T$ is singular and thus
does not have an inverse.
Observe that if \( TS \) is invertible then there
is an $M$ such that \( (TS)M=I \), so 
\( T(SM)=I \), and so \( T \) is invertible.
The contrapositive of that observation is that 
if \( T \) is not invertible then neither is \( TS \) \Dash 
if $\deter{T}=0$ then $\deter{TS}=0$.
%</pf:MatChVolByDetMat0>

%<*pf:MatChVolByDetMat1>
Now consider the case that $T$ is nonsingular. 
Any nonsingular matrix factors into a product 
of elementary matrices $T=E_1E_2\cdots E_r$.
To finish this argument 
we will verify that 
\( \deter{ES}=\deter{E}\cdot\deter{S} \)
for all matrices~$S$ and elementary matrices~$E$. 
The result will then follow because 
$\deter{TS}=\deter{E_1\cdots E_rS}=\deter{E_1}\cdots\deter{E_r}\cdot\deter{S}
  =\deter{E_1\cdots E_r}\cdot\deter{S}=\deter{T}\cdot\deter{S}$.
%</pf:MatChVolByDetMat1>

%<*pf:MatChVolByDetMat2>
There are three types of elementary matrix. 
We will cover the $M_i(k)$ case; 
the $P_{i,j}$ and $C_{i,j}(k)$ checks are similar.
The matrix $M_i(k)S$ equals $S$ except that row~$i$ is multiplied by $k$.
The third condition of determinant functions
then gives that $\deter{M_i(k)S}=k\cdot\deter{S}$.
But $\deter{M_i(k)}=k$, again by the third condition because
$M_i(k)$ is derived from the identity by multiplication of row~$i$ by
$k$. 
Thus \( \deter{ES}=\deter{E}\cdot\deter{S} \) holds for
$E=M_i(k)$.
%</pf:MatChVolByDetMat2>
\end{proof}


\begin{example}
Application of the map $t$ represented with respect to the standard  
bases by
\begin{equation*}
  \begin{mat}[r]
    1  &1  \\
   -2  &0
  \end{mat}
\end{equation*}
will double sizes of boxes, e.g., from this
\begin{center}
    \parbox{1.5in}{\hbox{}\hfil\includegraphics{det/mp/ch4.40}\hfil\hbox{}}  
    \quad
    $\begin{vmat}[r]
      2  &1  \\
      1  &2
    \end{vmat}=3$
\end{center}
to this
\begin{center}
    \parbox{1.5in}{\hbox{}\hfil\includegraphics{det/mp/ch4.41}\hfil\hbox{}}  
    \quad
    $\begin{vmat}[r]
        3  &3  \\
       -4  &-2
     \end{vmat}=6$
\end{center}
\end{example}


% Recall that determinants are not additive homomorphisms, that
% $\det(A+B)$ need not equal $\det(A)+\det(B)$.
% In contrast, the above theorem says that determinants are
% multiplicative homomorphisms:
% $\det(AB)$ equals $\det(A)\cdot \det(B)$.

\begin{corollary} \label{co:DeterminantOfInverseIsInverseOfDeterminant}
%<*co:DeterminantOfInverseIsInverseOfDeterminant>
If a matrix is invertible then the determinant of its inverse is the
inverse of its determinant $\deter{T^{-1}}=1/\deter{T}$.
%</co:DeterminantOfInverseIsInverseOfDeterminant>
\end{corollary}

\begin{proof}
%<*pf:DeterminantOfInverseIsInverseOfDeterminant>
$1=\deter{I}=\deter{TT^{-1}}=\deter{T}\cdot\deter{T^{-1}}$  
%</pf:DeterminantOfInverseIsInverseOfDeterminant>
\end{proof}


\begin{exercises}
  \item 
    Is
    \begin{equation*}
      \colvec[r]{4 \\ 1 \\ 2}
    \end{equation*}
    inside of the box formed by these three?
    \begin{equation*}
      \colvec[r]{3 \\ 3 \\ 1}
      \quad
      \colvec[r]{2 \\ 6 \\ 1}
      \quad
      \colvec[r]{1 \\ 0 \\ 5}
    \end{equation*}
    \begin{answer}
      Solving
      \begin{equation*}
        c_1\colvec[r]{3 \\ 3 \\ 1}
        +c_2\colvec[r]{2 \\ 6 \\ 1}
        +c_3\colvec[r]{1 \\ 0 \\ 5}
        =\colvec[r]{4 \\ 1 \\ 2}
      \end{equation*}
      gives the unique solution
      \( c_3=11/57 \), \( c_2=-40/57 \) and \( c_1=99/57 \).
      Because \( c_1>1 \), the vector is not in the box.  
    \end{answer}
  \recommended \item 
    Find the volume of the region defined by the vectors.
    \begin{exparts}
      \partsitem $\sequence{\colvec[r]{1 \\ 3},\colvec[r]{-1 \\ 4}}$
      \partsitem $\sequence{\colvec[r]{2 \\ 1 \\ 0},\colvec[r]{3 \\ -2 \\ 4},
                              \colvec[r]{8 \\ -3 \\ 8}}$
      \partsitem $\sequence{\colvec[r]{1 \\ 2 \\ 0 \\ 1},
                             \colvec[r]{2 \\ 2 \\ 2 \\ 2},
                             \colvec[r]{-1 \\ 3 \\ 0 \\ 5},
                             \colvec[r]{0 \\ 1 \\ 0 \\ 7}}$
    \end{exparts}
    \begin{answer}
      For each, find the determinant and take the absolute value.
      \begin{exparts*}
        \partsitem $7$
        \partsitem $0$
         % sage: A = matrix(QQ, [[2, 3, 8], [1, -2, -3], [0, 4, 8]])
         % sage: A
         % [ 2  3  8]
         % [ 1 -2 -3]
         % [ 0  4  8]
         % sage: det(A)
         % 0
        \partsitem $-58$
         % sage: A = matrix(QQ, [[1,2,-1,0], [2,2,3,1], [0,2,0,0], [1,2,5,7]])
         % sage: A
         % [ 1  2 -1  0]
         % [ 2  2  3  1]
         % [ 0  2  0  0]
         % [ 1  2  5  7]
         % sage: det(A)
         % -58
      \end{exparts*}
    \end{answer}
  \recommended \item 
    In this picture
    the rectangle on the left is defined by the points $(3,1)$ and
    $(1,2)$.  
    Apply the matrix to get the rectangle on the right, defined by 
    $(7,1)$ and $(4,2)$.
    Why doesn't this contradict
    \nearbytheorem{th:MatChVolByDetMat}?
    \begin{center}
      \begin{tabular}{c@{\hspace*{2em}}c@{\hspace*{2em}}c}
        \includegraphics{det/mp/ch4.43}
        &\raisebox{12pt}{\( \grstep{\bigl(\begin{smallmatrix}
                                        2  &1 \\
                                        0  &1
                                     \end{smallmatrix}\bigr)} \)}
        &\includegraphics{det/mp/ch4.44}                                 \\
        area is $2$
        &determinant is $2$
        &area is $3$
      \end{tabular}
    \end{center}
    \begin{answer}
      We have drawn that picture to mislead.
      The picture on the left is not the box formed by two vectors.
      If we slide it to the origin then it becomes the box formed by
      this sequence.
      \begin{equation*}
        \sequence{
          \colvec[r]{0 \\ 1},
          \colvec[r]{2 \\ 0}
       }
      \end{equation*}
      Then the image under the action of the matrix is the box formed
      by this sequence.
      \begin{equation*}
        \sequence{
          \colvec[r]{1 \\ 1},
          \colvec[r]{4 \\ 0}
         }
      \end{equation*}
      which has an area of $4$.
     \end{answer}
  \recommended \item 
    Find the volume of this region.
    \begin{center}
      \includegraphics{det/mp/ch4.42}  
    \end{center}
    \begin{answer}
      Move the parallelepiped to start at the origin,
      so that it becomes the box formed by 
      \begin{equation*}
        \sequence{
          \colvec[r]{3 \\ 0},
          \colvec[r]{2 \\ 1}
        }      
      \end{equation*}
      and now the absolute value of this determinant is 
      easily computed as $3$.
      \begin{equation*}
        \begin{vmat}[r]
          3  &2  \\
          0  &1
        \end{vmat}=3
      \end{equation*}
     \end{answer}
  \recommended \item 
    Suppose that \( \deter{A}=3 \).
    By what factor do these change volumes?
    \begin{exparts*}
      \partsitem \( A \)
      \partsitem \( A^2 \)
      \partsitem \( A^{-2} \)
    \end{exparts*}
    \begin{answer}
     \begin{exparts*}
        \partsitem \( 3 \)
        \partsitem \( 9 \)
        \partsitem $1/9$
      \end{exparts*}  
    \end{answer}
  \recommended \item
    Consider the linear transformation~$t$ of~$\Re^3$
    represented with respect to the 
    standard bases by this matrix.
    \begin{equation*}
      \begin{mat}
        1 &0 &-1 \\
        3 &1 &1 \\
       -1 &0 &3
      \end{mat}
    \end{equation*}
    \begin{exparts}
      \partsitem Compute the determinant of the matrix.
        Does the transformation preserve orientation or reverse it? 
      \partsitem Find the size of the box defined by these vectors.
        What is its orientation?
        \begin{equation*}
          \colvec{1 \\ -1 \\ 2}
          \quad
          \colvec{2 \\ 0 \\ -1}
          \quad
          \colvec{1 \\ 1 \\ 0}
        \end{equation*}
      \partsitem Find the images under $t$ of the vectors in the prior item and 
        find the size of the box that they define.
        What is the orientation?
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem
          Gauss's Method 
          \begin{equation*}
          \grstep[\rho_1+\rho_3]{-3\rho_1+\rho_2}
          \begin{mat}
            1 &0   &-1    \\
            0 &1   &4     \\
            0 &0   &2
          \end{mat}
          \end{equation*}
          gives the determinant as~$+2$.
          The sign is positive so the transformation preserves orientation.
        \partsitem
          The size of the box is the value of this determinant.
          \begin{equation*}
            \begin{vmat}
              1 &2  &1 \\
             -1 &0  &1 \\
              2 &-1 &0
            \end{vmat}
            =+6
          \end{equation*}
          The orientation is positive.
        \partsitem
          Since this transformation is represented by the given matrix with 
          respect
          to the standard bases, and with respect to 
          the standard basis the vectors represent themselves,
          to find the image of the vectors under the transformation just 
          multiply
          them, from the left, by the matrix.
          \begin{equation*}
            \colvec{1 \\ -1 \\ 2}\mapsto\colvec{-1 \\ 4 \\ 5}
            \qquad
            \colvec{2 \\ 0 \\ -1}\mapsto\colvec{3 \\ 5 \\ -5}
            \qquad
            \colvec{1 \\ 1 \\ 0}\mapsto\colvec{1 \\ 4 \\ -1}
          \end{equation*}
          Then compute the size of the resulting box.
          \begin{equation*}
            \begin{vmat}
              -1 &3  &1 \\
               4 &5  &4 \\
               5 &-5 &-1
            \end{vmat}
            =+12
          \end{equation*}
          The starting box is positively oriented, the transformation
          preserves orientations (since the determinant of the matrix is
          positive), and the ending box is also positively oriented.
      \end{exparts}
    \end{answer}
  \item 
    By what factor does each transformation change the size of
    boxes?
    \begin{exparts*}
      \partsitem $\colvec{x \\ y}\mapsto\colvec{2x \\ 3y}$
      \partsitem $\colvec{x \\ y}\mapsto\colvec{3x-y \\ -2x+y}$
      \partsitem $\colvec{x \\ y \\ z}\mapsto\colvec{x-y \\ x+y+z \\ y-2z}$
    \end{exparts*}
    \begin{answer}
      Express each transformation with respect to the standard bases
      and find the determinant. 
      \begin{exparts*}
        \partsitem $6$
        \partsitem $-1$
        \partsitem $-5$
      \end{exparts*}
    \end{answer}
  \item 
    What is the area of the image of the rectangle
    \( [2..4]\times [2..5] \) under the action of
    this matrix?
    \begin{equation*}
       \begin{mat}[r]
         2  &3  \\
         4  &-1
       \end{mat}
    \end{equation*}
    \begin{answer}
      The starting area is \( 6 \) and the matrix changes sizes by
      \( -14 \).
      Thus the area of the image is \( 84 \).  
    \end{answer}
  \item
     If \( \map{t}{\Re^3}{\Re^3} \) changes volumes by a factor of \( 7 \)
     and \( \map{s}{\Re^3}{\Re^3} \) changes volumes by a factor of \( 3/2 \)
     then by what factor will their composition changes volumes?
     \begin{answer}
        By a factor of \( 21/2 \).
     \end{answer}
  \item 
    In what way does the definition of a box differ from the
    definition of a span?
    \begin{answer}
      For a box we take a sequence of vectors (as described
      in the remark, the order of the vectors matters),
      while for a span we take a set of vectors.
      Also, for a box subset of $\Re^n$ there must be $n$ vectors; 
      of course for a span there can be any number of vectors.
      Finally, for a box the coefficients $t_1$,~\ldots, $t_n$
      are in the interval $[0..1]$, while for a 
      span the coefficients are free to range over all of $\Re$. 
    \end{answer}
  \item 
    Does \( \deter{TS}=\deter{ST} \)?
    \( \deter{T(SP)}=\deter{(TS)P} \)?
    \begin{answer}
      Yes to both.
      For instance, the first is \( \deter{TS}=\deter{T}\cdot\deter{S}=
                     \deter{S}\cdot\deter{T}=\deter{ST} \).  
    \end{answer}
  \item Show that there are no $\nbyn{2}$ matrices $A$ and~$B$ 
   satisfying these. % http://math.stackexchange.com/questions/827262/need-help-with-a-linear-algebra-proof
   \begin{equation*}
     AB=\begin{mat}[r]
       1 &-1 \\
       2  &0
     \end{mat}
     \quad
     BA=\begin{mat}[r]
       2 &1 \\
       1  &1
     \end{mat}
   \end{equation*}
   \begin{answer}  % due to math.stackexchange.com user dgrasines517
     Because $\deter{AB}=\deter{A}\cdot\deter{B}=\deter{BA}$ and these
     two matrices have different determinants.
   \end{answer}
  \item 
   \begin{exparts}
     \partsitem Suppose that \( \deter{A}=3 \) and that \( \deter{B}=2 \).
        Find \( \deter{A^2\cdot \trans{B}\cdot B^{-2}\cdot \trans{A} } \).
     \partsitem Assume that \( \deter{A}=0 \).
        Prove that \( \deter{6A^3+5A^2+2A}=0 \).
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem If it is defined then it is 
           \( (3^2)\cdot (2)\cdot (2^{-2})\cdot (3) \).
        \partsitem \( \deter{6A^3+5A^2+2A}=\deter{A}\cdot\deter{6A^2+5A+2I} \).
      \end{exparts}  
    \end{answer}
  \recommended \item
    Let \( T \) be the matrix representing (with respect to the standard
    bases) the map that rotates plane vectors counterclockwise through
    \( \theta \) radians.
    By what factor does \( T \) change sizes?
    \begin{answer}
       \(\begin{vmat}
                \cos\theta  &-\sin\theta  \\
                \sin\theta  &\cos\theta
              \end{vmat}=1 \)  
    \end{answer}
  \recommended \item
    Must a transformation \( \map{t}{\Re^2}{\Re^2} \) that preserves areas
    also preserve lengths?
    \begin{answer}
      No, for instance the determinant of 
      \begin{equation*}
        T=\begin{mat}[r]
          2  &0  \\
          0  &1/2
        \end{mat}
      \end{equation*}
      is \( 1 \) so it preserves areas, but the vector \( T\vec{e}_1 \)
      has length \( 2 \).  
    \end{answer}
  \item
    What is the volume of a parallelepiped in \( \Re^3 \) bounded by a
    linearly dependent set?
    \begin{answer}
       It is zero.  
    \end{answer}
  \recommended \item
    Find the area of the triangle in \( \Re^3 \) with endpoints
    \( (1,2,1) \), \( (3,-1,4) \), and \( (2,2,2) \).
    (This asks for area, not volume.
    The triangle defines a plane; what is the area of the triangle in that
    plane?)
    \begin{answer}
      Two of the three sides of the triangle are formed by these vectors.
      \begin{equation*}
        \colvec[r]{2 \\ 2 \\ 2}-\colvec[r]{1 \\ 2 \\ 1}=\colvec[r]{1 \\ 0 \\ 1}
        \qquad
        \colvec[r]{3 \\ -1 \\ 4}-\colvec[r]{1 \\ 2 \\ 1}=\colvec[r]{2 \\ -3 \\ 3}
      \end{equation*}
      One way to find the area of this triangle is to find half the volume of 
      the parallelogram formed by those two vectors and a length-one
      vector orthogonal to those two.
      To find the family of vectors orthogonal to those two we can
      start with the two relations
      \begin{equation*}
        \colvec[r]{1 \\ 0 \\ 1}
        \dotprod\colvec{x \\ y \\ z}
        =\colvec[r]{0 \\ 0 \\ 0}
        \qquad
        \colvec[r]{2 \\ -3 \\ 3}
        \dotprod\colvec{x \\ y \\ z}
        =\colvec[r]{0 \\ 0 \\ 0}
      \end{equation*}
      and solve the system
      \begin{equation*}
        \begin{linsys}{3}
          x  &   &   &+  &z  &=  &0  \\
         2x  &-  &3y &+  &3z &=  &0  
        \end{linsys}
        \grstep{-2\rho_1+\rho_2}
        \begin{linsys}{3}
          x  &   &   &+  &z  &=  &0  \\
             &   &-3y&+  &z  &=  &0  
        \end{linsys}
      \end{equation*}
      to get this solution set.
      \begin{equation*}
        \set{\colvec[r]{-1 \\ 1/3 \\ 1}z\suchthat z\in\Re}
      \end{equation*}
      Here is a length one solution.
      \begin{equation*}
        \frac{1}{\sqrt{19/9}}\cdot\colvec[r]{-1 \\ 1/3 \\ 1}
        =\colvec[r]{-3/\sqrt{19} \\ 1/\sqrt{19} \\ 3/\sqrt{19}}
      \end{equation*}
      Thus the area of the triangle is half of the absolute value of
      this determinant.
      \begin{equation*}
        \begin{vmat}[r]
             1  &2   &-3/\sqrt{19}   \\
             0  &-3  &1/\sqrt{19}   \\
             1  &3   &3/\sqrt{19}
        \end{vmat}
        =-19/\sqrt{19}
      \end{equation*} 
      Half of the absolute value is $\sqrt{19}/2$.
    \end{answer}
  \item \label{exer:DetProdEqProdDetsFcn}
    An alternate proof of \nearbytheorem{th:MatChVolByDetMat} uses 
    the definition of determinant functions.
    \begin{exparts}
      \partsitem Note that the vectors forming
        $S$ make a linearly dependent set if and only if 
        $\deter{S}=0$, and check that the result holds in this case.
      \partsitem For the $\deter{S}\neq 0$ case, to show that  
        $\deter{TS}/\deter{S}=\deter{T}$ for all transformations, consider
        the function
        \( \map{d}{\matspace_{\nbyn{n}}}{\Re} \) given by
        \( T\mapsto \deter{TS}/\deter{S} \).
        Show that $d$ has the first property of a determinant.
      \partsitem Show that $d$ has the remaining three properties of
        a determinant function.
      \partsitem Conclude that $\deter{TS}=\deter{T}\cdot\deter{S}$. 
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem Because the image of a linearly dependent set is 
          linearly dependent,
          if the vectors forming $S$ make a linearly dependent set, 
          so that $\deter{S}=0$,
          then the vectors forming $t(S)$ make a linearly dependent set,
          so that $\deter{TS}=0$, and in this case the equation holds.
        \partsitem We must check that if
          $T\smash[b]{\grstep{k\rho_i+\rho_j}}\hat{T}$ then 
          $d(T)=\deter{TS}/\deter{S}=\deter{\hat{T}S}/\deter{S}=d(\hat{T})$.
          We can do this by checking that combining rows first and
          then multiplying to get \( \hat{T}S \) gives the same result as
          multiplying first to get \( TS \) and then combining
          (because the determinant \( \deter{TS} \) is unaffected by the
          combining rows 
          so we'll then have that \( \deter{\hat{T}S}=\deter{TS} \) and
          hence that \( d(\hat{T})=d(T) \)).
          This check runs:~after adding 
          \( k \) times row~\( i \) of \( TS \) to
          row~$j$ of \( TS \), the \( j,p \) entry is
          \( (kt_{i,1}+t_{j,1})s_{1,p}+\dots+(kt_{i,r}+t_{j,r})s_{r,p} \),
          which is the \( j,p \) entry of \( \hat{T}S \).
        \partsitem For the second property, we need only check that swapping
          $T\smash[b]{\grstep{\rho_i\swap\rho_j}}\hat{T}$
          and then multiplying to get \( \hat{T}S \) gives the same result as
          multiplying \( T \) by \( S \) first and then swapping 
          (because,
          as the determinant \( \deter{TS} \) changes sign on
          the row swap, we'll then have \( \deter{\hat{T}S}=-\deter{TS} \),
          and so \( d(\hat{T})=-d(T) \)). 
          This check runs just like the one for the first property.

          For the third property, we need only show that performing
          $T\smash[b]{\grstep{k\rho_i}}\hat{T}$ 
          and then computing \( \hat{T}S \) gives the same result as
          first computing \( TS \) and then performing the scalar 
          multiplication
          (as the determinant \( \deter{TS} \) is rescaled by \( k \), 
          we'll have \( \deter{\hat{T}S}=k\deter{TS} \) and
          so \( d(\hat{T})=k\,d(T) \)).
          Here too, the argument runs just as above.

          The fourth property, that if $T$ is $I$ then the result is $1$, 
          is obvious.
        \partsitem Determinant functions are unique, so
          \( \deter{TS}/\deter{S}=d(T)=\deter{T} \),
          and so $\deter{TS}=\deter{T}\deter{S}$.
      \end{exparts}
    \end{answer}
%  \item  
%    Use the fact that
%    \( \deter{TS}=\deter{T}\,\deter{S} \)
%    to prove that if \( \phi \) and \( \sigma \) are \( n \)-permutations
%    then \( \sgn(\phi\sigma)=\sgn(\phi)\sgn(\sigma) \).
%    \cite{HoffmanKunze}
%    \begin{answer}
%       Take \( T=P_\phi \) and \( S=P_\sigma \).
%      Note that \( TS=P_{\phi\sigma} \) and so
%      \( \deter{P_{\phi\sigma}}=\deter{P_\phi}\cdot\deter{P_\sigma} \).  
%    \end{answer}
  \item 
    Give a non-identity matrix with the property that
    \( \trans{A}=A^{-1} \).
    Show that if \( \trans{A}=A^{-1} \) then \( \deter{A}=\pm 1 \).
    Does the converse hold?
    \begin{answer}
      Any permutation matrix has the property that the transpose of the
      matrix is its inverse.

      For the implication, we know that \( \deter{\trans{A}}=\deter{A} \).
      Then \( 1=\deter{A\cdot A^{-1}}=\deter{A\cdot\trans{A}}
               =\deter{A}\cdot\deter{\trans{A}}=\deter{A}^2 \).

      The converse does not hold; here is an example.
      \begin{equation*}
        \begin{mat}[r]
          3  &1  \\
          2  &1
        \end{mat}
      \end{equation*}
    \end{answer}
  \item 
    The algebraic 
    property of determinants that factoring a scalar out of a single
    row will multiply the determinant by that scalar shows that 
    where \( H \) is
    \( \nbyn{3} \), the determinant of \( cH \) is \( c^3 \) times the
    determinant of \( H \).
    Explain this geometrically, that is, 
    using \nearbytheorem{th:MatChVolByDetMat}.
    (The observation that increasing the linear size of a three-dimensional
    object by a factor of $c$ will increase its volume by a factor of 
    $c^3$ while only increasing its surface area by an amount proportional 
    to a factor of 
    $c^2$ is the \definend{Square-cube law}~\cite{Wikipedia}.)
    \begin{answer}
      Where the sides of the box are \( c \) times longer, the box
      has \( c^3 \) times as many cubic units of volume.  
    \end{answer}
  \item 
    We say that matrices $H$ and $G$ are 
    \definend{similar}\index{similar}\index{matrix!similar} 
    if there is a nonsingular matrix $P$ such that $H=P^{-1}GP$
    (we will study this relation in Chapter Five).
    Show that similar matrices have the same determinant.
    \begin{answer}
      If \( H=P^{-1}GP \)
      then \( \deter{H}=\deter{P^{-1}}\deter{G}\deter{P}
        =\deter{P^{-1}}\deter{P}\deter{G}=\deter{P^{-1}P}\deter{G}
        =\deter{G} \).  
    \end{answer}
  \item  \label{exer:BasisOrient}
    We usually represent vectors in \( \Re^2 \) with respect to the
    standard basis so vectors in the first quadrant have both coordinates
    positive.
    \begin{center}
      \parbox{.75in}{\hbox{}\hfil\includegraphics{det/mp/ch4.45}\hfil\hbox{}}
      \qquad
      \( \rep{\vec{v}}{\stdbasis_2}=\colvec[r]{+3 \\ +2} \)
    \end{center}
    Moving counterclockwise around the origin, we cycle through four regions:
    {\scriptsize
    \begin{equation*}
       \cdots
       \;\longrightarrow\colvec{+ \\ +}
       \;\longrightarrow\colvec{- \\ +}
       \;\longrightarrow\colvec{- \\ -}
       \;\longrightarrow\colvec{+ \\ -}
       \;\longrightarrow\cdots\,.
    \end{equation*} }
    Using this basis
    \begin{center}
      \( B=\sequence{\colvec[r]{0 \\ 1},\colvec[r]{-1 \\ 0}} \)
      \qquad
      \parbox{.75in}{\hbox{}\hfil\includegraphics{det/mp/ch4.46}\hfil\hbox{}}
    \end{center}
    gives the same counterclockwise cycle.
    We say these two bases have the same \emph{orientation}.\index{orientation}
    \begin{exparts}
      \partsitem Why do they give the same cycle?
      \partsitem What other configurations of unit vectors on the axes give the
        same cycle?
      \partsitem Find the determinants of the matrices formed from 
        those (ordered) bases.
      \partsitem What other counterclockwise cycles are possible, 
        and what are the
        associated determinants?
      \partsitem What happens in \( \Re^1 \)?
      \partsitem What happens in \( \Re^3 \)?
    \end{exparts}
    A fascinating general-audience
    discussion of orientations is in \cite{Gardner}.
    \begin{answer}
      \begin{exparts}
        \partsitem The new basis is the old basis rotated by \( \pi/4 \).
        \partsitem 
          $
             \sequence{\colvec[r]{-1 \\ 0},
                       \colvec[r]{0 \\ -1}}
          $, $
             \sequence{\colvec[r]{0 \\ -1},
                       \colvec[r]{1 \\ 0}}
          $
        \partsitem In each case the determinant is \( +1 \) 
          (we say that these bases
          have \definend{positive orientation}).
        \partsitem Because only one sign can change at a time, the only other
          cycle possible is
          \begin{equation*}
             \cdots
             \;\longrightarrow\colvec{+ \\ +}
             \;\longrightarrow\colvec{+ \\ -}
             \;\longrightarrow\colvec{- \\ -}
             \;\longrightarrow\colvec{- \\ +}
             \;\longrightarrow\cdots\,.
          \end{equation*}
          Here each associated determinant is \( -1 \)
          (we say that such bases have a \definend{negative orientation}).
        \partsitem There is one positively oriented basis \( \sequence{(1)} \)
          and one negatively oriented basis \( \sequence{(-1)} \).
        \partsitem There are \( 48 \) bases (\( 6 \) half-axis choices are
          possible for the first unit vector, \( 4 \) for the second, and
          \( 2 \) for the last).
          Half are positively oriented like the standard basis on the left 
          below,
          and half are negatively oriented like the one on the right
         \begin{center}
           \includegraphics{det/mp/ch4.47}
           \hspace*{4em}
           \includegraphics{det/mp/ch4.48}
          \end{center}
          In \( \Re^3 \) positive orientation is sometimes called 
          `right hand orientation' because if a person places their
          right hand
          with their fingers curling
          from \( \vec{e}_1 \) to \( \vec{e}_2 \) then the 
          thumb will point with \( \vec{e}_3 \).
      \end{exparts}  
    \end{answer}
%  \item 
%    A region of \( \Re^n \) is \definend{convex}\index{convex region} 
%    if for any two points
%    connecting that region, the line segment joining them lies entirely
%    inside the region (the inside of a sphere is convex, while the skin of a
%    sphere or a horseshoe is not).
%    Prove that boxes are convex.
%    \begin{answer}
%      Let \( \vec{p}=p_1\vec{v}_1+\dots +p_n\vec{v}_n \) and
%      \( \vec{q}=q_1\vec{v}_1+\dots +q_n\vec{v}_n \) be two vectors from a box
%      so that \( p_1,\dots,\,p_n,q_1,\dots,\,q_n\in [0..1] \).
%      The line segment between them is this.
%      \begin{equation*}
%        \set{t\cdot\vec{p}+(1-t)\cdot\vec{q}
%              \suchthat t\in [0..1]}
%        =\set{(tp_1+(1-t)q_1)\cdot\vec{v}_1+\dots+(tp_n+(1-t)q_n)\cdot\vec{v}_n
%              \suchthat t\in [0..1] }
%      \end{equation*}
%      Showing that each member of that set is in the box is routine.  
%    \end{answer}
  \item \label{exer:DetProdEqProdDetsPerms}
    \textit{This question uses material from 
      the optional Determinant Functions Exist subsection.}
    Prove \nearbytheorem{th:MatChVolByDetMat} by using the 
    permutation expansion formula for the determinant.
    \begin{answer}
      We will compare \( \det(\vec{s}_1,\dots,\vec{s}_n) \) with
      \( \det(t(\vec{s}_1),\dots,t(\vec{s}_n)) \) to show that the second
      differs from the first by a factor of $\deter{T}$.
      We represent the \( \vec{s}\, \)'s with respect to the standard bases
      \begin{equation*}
        \rep{\vec{s}_i}{\stdbasis_n}=
           \colvec{s_{1,i} \\ s_{2,i} \\ \vdots \\ s_{n,i}}
      \end{equation*}
      and then we represent the map application with 
      matrix-vector multiplication
      \begin{align*}
        \rep{\,t(\vec{s}_i)\,}{\stdbasis_n}
         &=\generalmatrix{t}{n}{n}
           \colvec{s_{1,j} \\ s_{2,j} \\ \vdots \\ s_{n,j}}     \\
         &=s_{1,j}\colvec{t_{1,1} \\ t_{2,1} \\ \vdots \\ t_{n,1}}
          +s_{2,j}\colvec{t_{1,2} \\ t_{2,2} \\ \vdots \\ t_{n,2}}
          +\dots
          +s_{n,j}\colvec{t_{1,n} \\ t_{2,n} \\ \vdots \\ t_{n,n}} \\
         &=s_{1,j}\vec{t}_1+s_{2,j}\vec{t}_2+\dots+s_{n,j}\vec{t}_n
      \end{align*}
      where \( \vec{t}_i \) is column~$i$ of \( T \).
      Then $\det(t(\vec{s}_1),\,\dots,\,t(\vec{s}_n))$ equals
      $
        \det(s_{1,1}\vec{t}_1\!+\!s_{2,1}\vec{t}_2\!
                +\!\dots\!+\!s_{n,1}\vec{t}_n,\,
             \dots,\,
             s_{1,n}\vec{t}_1\!+\!s_{2,n}\vec{t}_2
                \!+\!\dots\!+\!s_{n,n}\vec{t}_n)
     $.

     As in the derivation of the permutation expansion formula, we
     apply multilinearity, 
     first splitting along the sum in the first argument
     \begin{multline*}
         \det(s_{1,1}\vec{t}_1,\,
            \dots,\,
            s_{1,n}\vec{t}_1+s_{2,n}\vec{t}_2+\dots+s_{n,n}\vec{t}_n)  \\ 
        +\cdots{}                                             
        +\det(s_{n,1}\vec{t}_n,\,
           \ldots,\,
            s_{1,n}\vec{t}_1+s_{2,n}\vec{t}_2+\dots+s_{n,n}\vec{t}_n)
     \end{multline*}
     and then splitting each of those $n$ summands along the sums 
     in the second arguments, etc.
     We end with, as in the derivation of the permutation expansion, 
     \( n^n \) summand determinants, each of the form
     $\det(s_{i_1,1}\vec{t}_{i_1},s_{i_2,2}\vec{t}_{i_2},
            \,\dots,\,
            s_{i_n,n}\vec{t}_{i_n})$.
     Factor out each of the $s_{i,j}$'s
     $=
       s_{i_1,1}s_{i_2,2}\dots s_{i_n,n}
        \cdot\det(\vec{t}_{i_1},\vec{t}_{i_2},
       \,\dots,\,
       \vec{t}_{i_n})
      $.

      As in the permutation expansion derivation,
      whenever two of the indices in $i_1$, \ldots, $i_n$ are equal 
      then the determinant
      has two equal arguments, and evaluates to $0$. 
      So we need only consider the cases where $i_1$, \ldots, $i_n$ form a
      permutation of the numbers $1$, \ldots, $n$.
      We thus have
      \begin{equation*}
        \det(t(\vec{s}_1),\dots,t(\vec{s}_n))=
          \sum_{\text{permutations\ } \phi}
            s_{\phi(1),1}\dots s_{\phi(n),n}
            \det(\vec{t}_{\phi(1)},\dots,\vec{t}_{\phi(n)}).
      \end{equation*}
      Swap the columns in $\det(\vec{t}_{\phi(1)},\ldots,\vec{t}_{\phi(n)})$
      to get the matrix \( T \) back, which changes the sign by a factor of 
      $\sgn{\phi}$,
      and then factor out the determinant of $T$.
      \begin{equation*}
        =\sum_\phi
          s_{\phi(1),1}\dots s_{\phi(n),n}
            \det(\vec{t}_1,\dots,\vec{t}_n)\cdot\sgn{\phi}
        =\det(T)\sum_\phi
          s_{\phi(1),1}\dots s_{\phi(n),n}\cdot\sgn{\phi}.
      \end{equation*}
      As in the proof that the determinant of a matrix 
      equals the determinant 
      of its transpose, we commute the $s$'s to list them by ascending
      row number instead of by ascending column number
      (and we substitute $\sgn(\phi^{-1})$ for $\sgn(\phi)$).
      \begin{equation*}
        =\det(T)\sum_\phi
          s_{1,\phi^{-1}(1)}\dots s_{n,\phi^{-1}(n)}\cdot\sgn{\phi^{-1}}  
        =\det(T)\det(\vec{s}_1,\vec{s}_2,\dots,\vec{s}_n)
      \end{equation*}
    \end{answer}
%  \item 
%    Suppose that \( \map{f}{\matspace_{\nbyn{n}}}{\Re} \) is a non-constant
%    function with the property that \( f(GH)=f(G)f(H) \).
%    \begin{exparts}
%      \partsitem Show that \( f \) sends the identity to \( 1 \).
%      \partsitem Show that \( f \) maps the elementary matrix 
%        \( C_{i,j}(k) \) to \( 1 \)
%        (this matrix results from performing \( k\rho_i+\rho_j \) to the
%        identity).
%      \partsitem Show that 
%        \( f \) maps a row swap matrix to \( +1 \) or \( -1 \).
%    \end{exparts}
%    \begin{answer}
%      \begin{exparts}
%        \partsitem We have \( f(IH)=f(I)f(H) \) and \( f(IH)=f(H) \).
%        \partsitem
%        \partsitem A row swap matrix has the property that when 
%          done twice it equals
%          the identity.
%          But \( f(R)f(R)=f(RR)=f(I)=1 \) implies that \( f(R)=\pm 1 \).
%      \end{exparts} 
%     \end{answer}
  \recommended \item
    \begin{exparts}
      \partsitem Show that this gives 
        the equation of a line in \( \Re^2 \) through
        \( (x_2,y_2) \) and \( (x_3,y_3) \).
        \begin{equation*}
          \begin{vmat}
            x    &x_2 &x_3  \\
            y    &y_2 &y_3  \\
            1    &1   &1
          \end{vmat}=0
        \end{equation*}
      \partsitem \cite{Monthly55p249}
        Prove that the area of a triangle with vertices \( (x_1,y_1) \),
        \( (x_2,y_2) \), and \( (x_3,y_3) \) is
        \begin{equation*}
          \frac{1}{2}
          \begin{vmat}
            x_1  &x_2 &x_3  \\
            y_1  &y_2 &y_3  \\
            1    &1   &1
          \end{vmat}.
        \end{equation*}
      \partsitem \cite{MathMag73p286}
        Prove that the area of a triangle with vertices at \( (x_1,y_1) \),
        \( (x_2,y_2) \), and \( (x_3,y_3) \) whose coordinates are integers
        has an area of \( N \) or \( N/2 \) for some positive integer \( N \).
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem An algebraic check is easy.
        \begin{equation*}
          0
          =xy_2+x_2y_3+x_3y-x_3y_2-xy_3-x_2y 
          =x\cdot (y_2-y_3)+y\cdot (x_3-x_2)+x_2y_3-x_3y_2 
        \end{equation*}
        simplifies to the familiar form
        \begin{equation*}
          y=x\cdot (x_3-x_2)/(y_3-y_2)+(x_2y_3-x_3y_2)/(y_3-y_2)
        \end{equation*}
        (the $y_3-y_2=0$ case is easily handled).

        For geometric insight, this 
        picture shows that the box formed by the three vectors.
        Note that all 
        three vectors end in the $z=1$ plane.
        Below the two vectors on the right is the line through
        $(x_2,y_2)$ and $(x_3,y_3)$.
        \begin{center}
          \includegraphics{det/mp/ch4.49}
        \end{center}
        The box will 
        have a nonzero volume unless the triangle formed by the ends of the
        three is degenerate.
        That only happens (assuming that $(x_2,y_3)\neq (x_3,y_3)$)
        if  $(x,y)$ lies on the line through the other two. 
       \partsitem \answerasgiven %
        We find the altitude through $(x_1,y_1)$ of a triangle with vertices
        $(x_1,y_1)$ $(x_2,y_2)$ and $(x_3,y_3)$ in the usual
        way from the normal form of the above:
        \begin{equation*}
          \frac{1}{\sqrt{(x_2-x_3)^2+(y_2-y_3)^2}}
          \begin{vmat}
            x_1  &x_2  &x_3  \\
            y_1  &y_2  &y_3  \\
            1    &1    &1
          \end{vmat}.
        \end{equation*}
        Another step shows the area of the triangle to be
        \begin{equation*}
          \frac{1}{2}
          \begin{vmat}
            x_1  &x_2  &x_3  \\
            y_1  &y_2  &y_3  \\
            1    &1    &1
          \end{vmat}.
        \end{equation*}
        This exposition reveals the \textit{modus operandi} more clearly
        than the usual proof of showing a collection of terms to be identical
        with the determinant.
       \partsitem  \answerasgiven %
        Let
        \begin{equation*}
          D=
          \begin{vmat}
            x_1  &x_2  &x_3  \\
            y_1  &y_2  &y_3  \\
            1    &1    &1
          \end{vmat}
        \end{equation*}
        then the area of the triangle is $(1/2)\deter{D}$.
        Now if the coordinates are all integers, then $D$ is an integer.
      \end{exparts}
    \end{answer}
\end{exercises}
